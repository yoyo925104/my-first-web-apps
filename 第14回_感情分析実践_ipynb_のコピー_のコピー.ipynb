{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoyo925104/my-first-web-apps/blob/main/%E7%AC%AC14%E5%9B%9E_%E6%84%9F%E6%83%85%E5%88%86%E6%9E%90%E5%AE%9F%E8%B7%B5_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA0MzIZiYpUU"
      },
      "source": [
        "# Python で日本語文章の感情分析\n",
        "## huggingface の bert-base-japanese-sentiment\n",
        "\n",
        "- [huggingface の bert-japanese-finetuned-sentiment](https://huggingface.co/koheiduck/bert-japanese-finetuned-sentiment)\n",
        "    - 解説記事: [bert-base-japanese-sentiment モデル作者の BERT HANDSON 資料](https://github.com/ydaigo/BERT_HANDSON/blob/master/BERT_HANDS_ON.ipynb)\n",
        "    - ネガポジ判定 (ポジティヴとネガティヴの binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m26RzJ5baFP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb619dac-29ef-4737-a2e0-991f3440b564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.22.4)\n",
            "Requirement already satisfied: pyre-extensions==0.0.29 in /usr/local/lib/python3.10/dist-packages (from xformers) (0.0.29)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers) (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->xformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->xformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->xformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyre-extensions==0.0.29->xformers) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "# 必要なライブラリのインストール\n",
        "!pip install -q transformers\n",
        "!pip install ipadic\n",
        "!pip install fugashi\n",
        "!pip install xformers\n",
        "!pip install unidic-lite # 20250107コード定義変更のため追記\n",
        "# !pip install sentencepiece\n",
        "# !pip install janome fasttext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリのインポート\n",
        "\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification, pipeline"
      ],
      "metadata": {
        "id": "6UTIfsWlRVra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('koheiduck/bert-japanese-finetuned-sentiment')\n",
        "\n",
        "# Load the model\n",
        "model = BertForSequenceClassification.from_pretrained('koheiduck/bert-japanese-finetuned-sentiment')"
      ],
      "metadata": {
        "id": "U4YX987jOAmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94SGBozdajiA",
        "outputId": "f8a0c68e-ba3c-44d6-c319-5f46acb6bc3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9851733446121216}]\n"
          ]
        }
      ],
      "source": [
        "# シンプルな動作確認\n",
        "# pipeline(\"やりたい処理方法\", model=利用したいモデル, tokenizer=利用したいトーカナイザー)(判定したい文章)\n",
        "# labelでは「ポジティブ or ネガティブ」が出力される\n",
        "# scoreにはlabelで出た極性の度合いが1を最大値として出力される\n",
        "\n",
        "print(pipeline(\"sentiment-analysis\",model=model, tokenizer=tokenizer)(\"私は幸福である。\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline(\"sentiment-analysis\",model=model, tokenizer=tokenizer)(\"難題にぶつかって頭を抱えている。\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSHCyGBTh1me",
        "outputId": "3ccfae5d-c0c5-4bf0-d4e0-904c445566b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.9908578991889954}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list_textの中に幾つかの文章を入れ込んで、それらの感情分析を順番に行う\n",
        "\n",
        "list_text = [\n",
        "             'この人は、この世の中で、いちばんしあわせな人にちがいありません。',\n",
        "             '芝居小屋もすばらしいし、お客さんもすばらしい人たちでした。',\n",
        "             'もし中世の時代だったら、おそらく、火あぶりにされたでしょうよ。',\n",
        "             'みんなのうるさいことといったら、まるで、ハエがびんの中で、ブンブンいっているようでした。',\n",
        "             'われわれ人間が、こういうことを考えだすことができるとすれば、われわれは、地の中にうめられるまでに、もっと長生きできてもいいはずだが'\n",
        "]"
      ],
      "metadata": {
        "id": "fuZVmG2al2oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list_text:\n",
        "  print(i)\n",
        "  print(pipeline(\"sentiment-analysis\",model=model, tokenizer=tokenizer)(i))\n",
        "  print(\"==============================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9aUtUHZ4z6T",
        "outputId": "9791a8cf-390b-463d-db8f-9f0e28ae4581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "この人は、この世の中で、いちばんしあわせな人にちがいありません。\n",
            "[{'label': 'POSITIVE', 'score': 0.8791817426681519}]\n",
            "==============================\n",
            "芝居小屋もすばらしいし、お客さんもすばらしい人たちでした。\n",
            "[{'label': 'POSITIVE', 'score': 0.9705815315246582}]\n",
            "==============================\n",
            "もし中世の時代だったら、おそらく、火あぶりにされたでしょうよ。\n",
            "[{'label': 'NEGATIVE', 'score': 0.8034874200820923}]\n",
            "==============================\n",
            "みんなのうるさいことといったら、まるで、ハエがびんの中で、ブンブンいっているようでした。\n",
            "[{'label': 'NEGATIVE', 'score': 0.5459651947021484}]\n",
            "==============================\n",
            "われわれ人間が、こういうことを考えだすことができるとすれば、われわれは、地の中にうめられるまでに、もっと長生きできてもいいはずだが\n",
            "[{'label': 'NEUTRAL', 'score': 0.5141775608062744}]\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_rows = []\n",
        "\n",
        "for i in list_text:\n",
        "    label = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)(i)[0][\"label\"]\n",
        "    score = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)(i)[0][\"score\"]\n",
        "    output_rows.append([label, score])\n",
        "\n",
        "output_rows"
      ],
      "metadata": {
        "id": "dDlpmm5T5xUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30a6a78-a78d-469a-c472-904d8458f502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['POSITIVE', 0.8791817426681519],\n",
              " ['POSITIVE', 0.9705815315246582],\n",
              " ['NEGATIVE', 0.8034874200820923],\n",
              " ['NEGATIVE', 0.5459651947021484],\n",
              " ['NEUTRAL', 0.5141775608062744]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the path and filename for the CSV file\n",
        "csv_file = \"./output.csv\"\n",
        "\n",
        "# Write the output_rows to the CSV file\n",
        "with open(csv_file, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(output_rows)"
      ],
      "metadata": {
        "id": "IZUMa1J97N5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "無機質な単語や短いセンテンスだとどうなるのか？"
      ],
      "metadata": {
        "id": "DQl_CWg47QvO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvY1otPrazoP",
        "outputId": "0b2b2550-8b08-4300-fa52-7faee1a1dbb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'NEGATIVE', 'score': 0.9927927255630493}],\n",
              " [{'label': 'NEGATIVE', 'score': 0.9867493510246277}],\n",
              " [{'label': 'POSITIVE', 'score': 0.9866198301315308}],\n",
              " [{'label': 'NEUTRAL', 'score': 0.9328478574752808}],\n",
              " [{'label': 'NEUTRAL', 'score': 0.6107232570648193}]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "list(map(pipeline(\"sentiment-analysis\",model=model, tokenizer=tokenizer), ['最悪だ', '暑い', \"楽しい\", 'こんにちは', '足']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIyfVNa5bK49"
      },
      "source": [
        "最悪、暑いなどはネガティブに捉えられていて、私たちの感覚と相違はなさそう。\n",
        "\n",
        "こんにちは、足、などには感情を人間も感じないように、機会も感じない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QciH4YRDhBf"
      },
      "source": [
        "## まとめ\n",
        "\n",
        "日本語文章の感情分析を簡単にできるツールを試してみました。\n",
        "\n",
        "こういったツールを公開していただけていることに感謝ですね。\n",
        "\n",
        "真面目に感情分析やって、もっと妥当な結果を出そうとすると、トレーニングデータセットを充実させたり、さらに工夫が必要になりそうです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6shDWHlEPd4"
      },
      "source": [
        "## 参考\n",
        "\n",
        "### 解説、まとめ記事\n",
        "\n",
        "- [【27個掲載】文章、表情、音声の感情分析に使えるデータセットまとめ | Lionbridge AI](https://lionbridge.ai/ja/datasets/15-free-sentiment-analysis-datasets-for-machine-learning/)\n",
        "    - リソースや極性辞書へのリンクなど\n",
        "- [筑波大学 乾先生の感情分析リンクまとめ](http://www.nlp.mibel.cs.tsukuba.ac.jp/~inui/SA/links.html)\n",
        "- [【自然言語処理】感情分析の進め方＆ハマりやすいポイント - Qiita](https://qiita.com/toshiyuki_tsutsui/items/604f92dbe6e20a18a17e)\n",
        "- [日本語 Sentiment Analyzer を作ってパッケージ化した話 - Ahogrammer](https://hironsan.hatenablog.com/entry/japanese-sentiment-analyzer)\n",
        "- [ディープラーニングを使って転職会議の企業クチコミデータを感情分析してみる - Qiita](https://qiita.com/terrierscript/items/54daa5aedde599e2637c)\n",
        "- [小説「天気の子」を丸ごと一冊、感情分析してみた☔️ - Qiita](https://qiita.com/toshiyuki_tsutsui/items/10f52c30fe1504b83ba1)\n",
        "- [日本語評価極性辞書を利用したPython用Sentiment Analysisライブラリ oseti を公開しました - Qiita](https://qiita.com/yukinoi/items/46aa016d83bb0e64f598)\n",
        "- [ML-Askでテキストの感情分析 - Qiita](https://qiita.com/yukinoi/items/ef6fb48b5e3694e9659c)\n",
        "- [bert-base-japanese-sentiment モデル作者の BERT HANDSON 資料](https://github.com/ydaigo/BERT_HANDSON/blob/master/BERT_HANDS_ON.ipynb)\n",
        "\n",
        "### 感情分析日本語データセット\n",
        "\n",
        "- [SNOW D18:日本語感情表現辞書 - 長岡技術科学大学 自然言語処理研究室](http://www.jnlp.org/SNOW/D18)\n",
        "    - 長岡技術科学大学 自然言語処理研究室\n",
        "    - 約2,000表現を収録し、各表現に対して我々が独自に定義した48分類の感情を付与"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MM1vuf6wWky-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}